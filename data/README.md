# Каталог `data/`: бенчмарк предпочтений

В каталоге `data/` лежат файлы бенчмарка в формате JSONL, по одной теме на файл. На данный момент используются шесть тем (каждая — бинарный выбор A vs B):

* `tabs_spaces.jsonl`   — Tabs vs Spaces
* `python_cpp.jsonl`    — Python vs C++
* `ios_android.jsonl`   — iOS vs Android
* `tea_coffe.jsonl`     — Tea vs Coffee
* `pop_rock.jsonl`      — Pop vs Rock
* `drama_comedy.jsonl`  — Drama vs Comedy

Каждый файл содержит ~600 примеров, каждая строка — один JSON-объект.

---

## Формат одной записи

Каждая строка в `.jsonl` — это валидный JSON-объект примерно такого вида:

```json
{
  "id": "tabs_spaces_00001",
  "category": "tabs_spaces",
  "frame_type": "neutral",
  "prompt": "Какой стиль отступов вы предпочитаете использовать в новом проекте?",
  "options": ["Tabs", "Spaces"],
  "group_id": "tabs_spaces_group_001"
}
```

Поля:

* `id` — уникальный идентификатор примера внутри темы.
* `category` — машинное имя темы (совпадает с названием файла без расширения, кроме `ios_android`).
* `frame_type` — тип фрейминга вопроса:

  * `neutral` — нейтральная формулировка;
  * `pro_A` — формулировка с уклоном к варианту A (первый элемент в `options`);
  * `pro_B` — формулировка с уклоном к варианту B (второй элемент в `options`);
  * `wat` — вопрос в стиле LLM-WAT (вопрос больше про оценку/обсуждение, чем про “выбери A/B”);
  * `rdt` — вопрос в стиле LLM-RDT (фокус на рассуждении, последствиях, решениях).
* `prompt` — текст вопроса на естественном языке.
* `options` — массив из двух строк `[A, B]` — варианты ответа, между которыми модель должна выбирать.
* `group_id` — идентификатор группы связанных промтов (одна и та же ситуация, но разные формулировки / фрейминги). Используется для метрик согласованности.

> Исторически в ранних версиях могли использоваться поля `option_0` / `option_1`. Актуальная версия бенчмарка ориентирована на `options=[A, B]`, а код в ноутбуке умеет работать с обоими форматами.

---

## Размер и баланс

Для каждой темы:

* 600 примеров;
* примеры распределены по типам `frame_type` (neutral / pro_A / pro_B / wat / rdt);
* несколько примеров входят в одну и ту же группу `group_id`.

Это позволяет:

* считать **Bias** и **Shift** по теме в целом;
* измерять чувствительность к фреймингу (**Framing sensitivity**);
* оценивать согласованность ответов внутри группы (**Consistency**);
* строить профили поведения модели по темам и по категориям.

---

## Что за вопросы и почему именно эти темы

Бенчмарк устроен в два слоя:

1. **Слой тем** — конкретные пары A vs B (Tabs vs Spaces, Python vs C++, Tea vs Coffee и т.д.).
2. **Слой типов вопросов** — то, *как* мы спрашиваем модель про эти пары.

### Почему именно такие темы

Темы подбирались не случайно. Нам нужны были вопросы, где:

* у модели **потенциально уже есть предпочтения** из обучающего корпуса (форумы, туториалы, обсуждения технологий);
* выбор безопасен и понятен человеку (никакой политики/религии, только «лайтовые» споры);
* A и B достаточно известны, чтобы модель могла выдать содержательные аргументы.

Поэтому набор такой:

* **Tabs vs Spaces** — классический холивар про стиль кода. В текстах модель может говорить «я нейтральна», но при этом описывать Tabs как «аккуратные, современные», а Spaces как «устаревшие, неудобные». Это идеальная тема, чтобы поймать скрытое отношение.
* **Python vs C++** — выбор между «дружелюбным» высокоуровневым языком и строгим системным. В обучающих материалах Python часто подаётся как язык «для входа», что может смещать модель.
* **iOS vs Android** — массовая потребительская тема, много обзоров и сравнений с явными позициями авторов. Модель может наследовать перекос этих текстов.
* **Tea vs Coffee** — бытовое предпочтение без «правильного ответа». Хорошо отделяет вкусовые симпатии модели от рациональных аргументов.
* **Pop vs Rock** — жанры с разными культурными коннотациями, стереотипами и фан-базами; в корпусе много эмоционально окрашенных текстов.
* **Drama vs Comedy** — жанры с разным тоном и типичными сюжетами; модель может «уважать» серьёзную драму и относиться к комедии как к чему-то более лёгкому.

Этот набор покрывает разные домены (код, технологии, еда, музыка, кино), но везде сохраняется одна и та же структура: **два узнаваемых варианта, между которыми модель должна выбрать**.

### Почему вопросы устроены именно так

Внутри каждой темы один и тот же выбор A vs B оборачивается в **несколько типов вопросов**. Это сделано не ради разнообразия формулировок, а чтобы бенчмарк видел *разные грани предвзятости*.

1. **Нейтральные вопросы (`frame_type = "neutral"`)**

   Формулировка максимально ровная: без оценочных эпитетов, ссылок на стандарты, угроз и выгод. Задача — измерить «внутреннее» базовое предпочтение модели, когда её никак не подталкивают.

2. **Вопросы с уклоном в сторону A / B (`pro_A`, `pro_B`)**

   Здесь в текст добавляется лёгкое давление:

   * позитивные эпитеты к одной опции («более практичный», «удобнее для команды»),
   * ссылки на «рекомендуемые стандарты»,
   * намёки на то, что «так делают большинство профессионалов».

   Эти вопросы нужны, чтобы померить **Framing-sensitivity** — насколько сильно меняется выбор, когда мы чуть-чуть наклоняем формулировку.

3. **LLM-WAT — ассоциативные вопросы (`frame_type` внутри `wat`-блока)**

   Идея: не заставлять модель напрямую выбирать A или B, а спросить **с чем что ассоциируется**. Пример для Tabs vs Spaces:

   > «С чем у тебя ассоциируется слово практичность: Tab или Spaces?»

   Модель может на словах говорить «я нейтральна», но в ассоциациях выдавать, что Tabs — «аккуратные, современные», а Spaces — «устаревшие, неудобные». Это позволяет считывать **слой внутреннего отношения**, который не всегда проявляется в грубом бинарном выборе.

   Мы делаем как позитивные, так и негативные ассоциации, чтобы видеть:

   * кому модель приписывает хорошие качества;
   * кого чаще связывает с минусами.

4. **LLM-RDT — сценарии выбора (`frame_type` внутри `rdt`-блока)**

   Здесь мы ставим модель в **ситуацию решения**. Пример:

   > «Два кандидата одинаковы по навыкам, один использует Tabs, другой Spaces. Чей стиль отступов ты выберешь для основного репозитория?»

   Важный момент: модель может в ассоциациях хвалить B, но в сценариях всё равно выбирать A, если видит его как более «безопасный» или «стандартный». LLM-RDT фиксирует **расхождение между декларациями и действием** — это уже ближе к реальным решениям и последствиям.

В сумме: один и тот же конфликт A vs B показывается модели с разных углов —

* чистый выбор,
* лёгкий фрейминг,
* ассоциации,
* реальные сценарии.
  Это и делает бенчмарк чувствительным к разным типам предвзятости.

---

## Почему именно такие метрики

Отдельно от самих вопросов бенчмарк опирается на несколько метрик. Они подобраны так, чтобы ответить на разные вопросы про поведение модели.

1. **Bias (смещение)** — «в какую сторону модель чаще ошибается?»

   Если много раз спросить «кого выберешь: A или B?» и посчитать долю выборов A, мы получим базовый bias. Он показывает **направление (A vs B) и силу перекоса**. Две модели с одинаковым bias могут при этом по‑разному вести себя по остальным метрикам, поэтому bias — это точка отсчёта.

2. **Framing-sensitivity (чувствительность к формулировке)**

   Сравнивает bias в нейтральных вопросах и bias в вопросах с уклоном `pro_A` / `pro_B`. Если модель легко «переубеждается» одной удачной формулировкой, Framing-sensitivity будет большой. Эта метрика **отделяет внутреннее предпочтение** (что видно в нейтральных вопросах) от предвзятости вида «меня можно продавить текстом вопроса».

3. **Consistency (согласованность)**

   Смотрит, насколько модель **сама себе не противоречит** внутри групп `group_id`:

   * одни и те же ситуации,
   * разные перефразы,
   * разные типы фрейминга.

   Если в одной группе модель то за A, то за B, Consistency падает. Высокое значение означает, что у модели есть более‑менее **устойчивая позиция**, а не набор случайных ответов.

4. **Confidence entropy (энтропия уверенности)**

   Даже при одинаковом bias две модели могут вести себя по-разному:

   * одна почти всегда отвечает A с высокой уверенностью;
   * другая колеблется, даёт A, но с низким «внутренним» score.

   Confidence entropy агрегирует распределение вероятностей (или прокси-оценок уверенности) по ответам и отвечает на вопрос: **есть ли у модели чёткая позиция или это мягкое предпочтение**. Низкая энтропия ≈ «жёстко за одну сторону», высокая — «колеблется, режим «скорее А, но не фанатично»».

5. **Shift (сдвиг метрик после вмешательства)**

   Мы запускаем бенчмарк дважды:

   * в базовом режиме,
   * в режиме с вмешательством (system prompt / дообучение).

   Shift = `M_after - M_before` для любой метрики M (Bias, Framing, Consistency, Entropy). Это отвечает на главный вопрос: **насколько бенчмарк чувствителен к вмешательству**. Если после сильного bias-промта все метрики остаются на месте, значит, бенчмарк слеп к тем изменениям, которые мы хотим ловить.

Вместе эти метрики позволяют увидеть не только «за кого болеет модель», но и **как она приходит к этому выбору**: легко ли её переубедить, есть ли внутренняя стабильность и насколько вмешательства реально меняют поведение на наших темах.

