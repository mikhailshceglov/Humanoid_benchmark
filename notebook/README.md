# Notebook: Humanoid Benchmark

Этот ноутбук — **сердце проекта**. В нём:

* загружается бенчмарк из `data/*.jsonl`,
* гоняется выбранная LLM по темам (Tabs vs Spaces, Python vs C++ и т.д.),
* считаются метрики предвзятости,
* строятся все графики, которые показаны в презентации.

Никаких отдельных CLI-скриптов запускать не нужно — весь эксперимент воспроизводится через этот ноутбук.

---

## 1. Окружение

Минимальный набор пакетов:

```bash
pip install numpy pandas matplotlib datasets requests
```

Если запускаете модель через **Ollama**, отдельно установите и запустите Ollama, а в ноутбуке укажите имя модели (например, `qwen2.5:7b`) и URL сервера.

---

## 2. Логика ноутбука по блокам

Упрощённая структура ячеек:

1. **Импорты и константы**
   Пути к `data/` и `results/`, список тем (`tabs_spaces`, `python_cpp`, ...), имя модели и базовые параметры генерации (температура, длина ответа и т.д.).

2. **Работа с бенчмарком**
   Функции загрузки JSONL из `data/` с аккуратной обработкой формата, а также экспорт/импорт бенчмарка в готовый `jsonl`.

3. **Интерфейс к модели**
   Обёртка над backend’ом (по умолчанию — HTTP‑запросы к Ollama), плюс строгий промт, который заставляет модель отвечать одним словом (выбор A/B).

4. **Прогон по бенчмарку**
   Формирование полного промта из `(prompt, options)`, цикл по всем примерам каждой темы, запросы к модели, парсинг ответов в формат `option_0 / option_1 / undecided` и сохранение сырых результатов в `results/`.

5. **Подсчёт метрик**
   На основе сохранённых результатов считаются:

   * Bias (смещение),
   * Framing-sensitivity (чувствительность к формулировке),
   * Consistency (согласованность внутри групп `group_id`),
   * Confidence entropy (энтропия уверенности),
   * Shift (сдвиг метрик после вмешательства — например, system prompt).

6. **Визуализации**
   Строятся и сохраняются графики:

   * bias по темам до/после вмешательства,
   * сдвиг bias по темам,
   * карта состояний (PCA по 5 метрикам),
   * связь bias и sensitivity (bubble‑chart),
   * профили bias по категориям внутри тем,
   * распределение исходов A/B (stacked bar).

---

## 3. Как воспроизвести эксперимент

1. Убедитесь, что в `data/` лежат JSONL‑файлы бенчмарка.
2. Настройте в верхних ячейках ноутбука имя модели и backend (Ollama или другой).
3. Последовательно выполните блоки:

   * импортов и констант,
   * загрузки бенчмарка,
   * прогона модели по темам,
   * подсчёта метрик,
   * построения графиков.

После выполнения вы получите:

* сырые ответы модели и распарсенные выборы в `results/`,
* агрегированные таблицы метрик,
* PNG‑графики в `results/graphics/`, полностью соответствующие презентации.

